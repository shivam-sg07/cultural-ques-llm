{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8dcbed-cbf7-4490-afe8-94645586cc66",
   "metadata": {},
   "source": [
    "# Load required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952959b-949f-4a47-9aaf-0291aa537289",
   "metadata": {},
   "source": [
    "To install the packages required for this notebook on the HPC, please follow the 'Jupyter Kernel Creation' slides posted on OPAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e6069a-b4e4-47e9-9bf5-97a6919c0810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/horse/ws/gadh722g-llm_project/llm_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load required packages\n",
    "import re\n",
    "import ast\n",
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm as notebook_tqdm\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2871201d-a536-444b-ace6-c5f17ea5f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"YOUR_HF_TOKEN_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638db0ec-f4a8-4408-9131-82abfbcf140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load the raw training file\n",
    "df_train = pd.read_csv(\"train_dataset_saq.csv\")\n",
    "\n",
    "# 2. Parse the 'annotations' column to extract the answer\n",
    "def extract_answer(row):\n",
    "    try:\n",
    "        # Convert string representation of list to actual list\n",
    "        data = ast.literal_eval(row['annotations'])\n",
    "        # Get the first answer from the list\n",
    "        return data[0]['answers'][0]\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df_train['clean_answer'] = df_train.apply(extract_answer, axis=1)\n",
    "\n",
    "# 3. Format into the Prompt Structure\n",
    "# We train the model to output the EXACT format we want.\n",
    "def formatting_prompts_func(examples):\n",
    "    output_texts = []\n",
    "    for q, c, a in zip(examples['en_question'], examples['country'], examples['clean_answer']):\n",
    "        # The prompt template\n",
    "        text = f\"Question: {q}\\nCountry: {c}\\nAnswer: {a}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "# 4. Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "print(f\"Training on {len(train_dataset)} examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9228837-486a-468b-b70e-9d7bcf8e13a3",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea4dd0a-97ef-47a5-b551-7f13bf8f145f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>question</th>\n",
       "      <th>en_question</th>\n",
       "      <th>annotations</th>\n",
       "      <th>idks</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Na-ko-25</td>\n",
       "      <td>درایران ورزش‌های معمولی که در روز ورزش مدارس ا...</td>\n",
       "      <td>What are the typical sports played in Iran's s...</td>\n",
       "      <td>[{'answers': ['فوتبال'], 'en_answers': ['footb...</td>\n",
       "      <td>{'idk': 0, 'no-answer': 0, 'not-applicable': 0}</td>\n",
       "      <td>IR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New-en-79</td>\n",
       "      <td>Which region of the UK is well known for its t...</td>\n",
       "      <td>Which region of UK is well known for its theat...</td>\n",
       "      <td>[{'answers': ['london'], 'en_answers': ['londo...</td>\n",
       "      <td>{'idk': 0, 'no-answer': 0, 'not-applicable': 0}</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al-en-16</td>\n",
       "      <td>At what age do kids start nursery in the UK? (...</td>\n",
       "      <td>At what age do kids start preschool in UK? (Pr...</td>\n",
       "      <td>[{'answers': ['3'], 'en_answers': ['3'], 'coun...</td>\n",
       "      <td>{'idk': 0, 'no-answer': 0, 'not-applicable': 0}</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New-as-89</td>\n",
       "      <td>What traditional festival accessories do peopl...</td>\n",
       "      <td>What traditional festival accessories do peopl...</td>\n",
       "      <td>[{'answers': ['fourth of july clothes'], 'en_a...</td>\n",
       "      <td>{'no-answer': 2, 'not-applicable': 2, 'idk': 1}</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gu-ch-32</td>\n",
       "      <td>در کشور شما مدت زمان آموزش اجباری به سال چقدر ...</td>\n",
       "      <td>What is the duration of compulsory education i...</td>\n",
       "      <td>[{'answers': ['8'], 'en_answers': ['8'], 'coun...</td>\n",
       "      <td>{'no-answer': 1, 'idk': 1, 'not-applicable': 0}</td>\n",
       "      <td>IR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           question  \\\n",
       "0   Na-ko-25  درایران ورزش‌های معمولی که در روز ورزش مدارس ا...   \n",
       "1  New-en-79  Which region of the UK is well known for its t...   \n",
       "2   Al-en-16  At what age do kids start nursery in the UK? (...   \n",
       "3  New-as-89  What traditional festival accessories do peopl...   \n",
       "4   Gu-ch-32  در کشور شما مدت زمان آموزش اجباری به سال چقدر ...   \n",
       "\n",
       "                                         en_question  \\\n",
       "0  What are the typical sports played in Iran's s...   \n",
       "1  Which region of UK is well known for its theat...   \n",
       "2  At what age do kids start preschool in UK? (Pr...   \n",
       "3  What traditional festival accessories do peopl...   \n",
       "4  What is the duration of compulsory education i...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{'answers': ['فوتبال'], 'en_answers': ['footb...   \n",
       "1  [{'answers': ['london'], 'en_answers': ['londo...   \n",
       "2  [{'answers': ['3'], 'en_answers': ['3'], 'coun...   \n",
       "3  [{'answers': ['fourth of july clothes'], 'en_a...   \n",
       "4  [{'answers': ['8'], 'en_answers': ['8'], 'coun...   \n",
       "\n",
       "                                              idks country  \n",
       "0  {'idk': 0, 'no-answer': 0, 'not-applicable': 0}      IR  \n",
       "1  {'idk': 0, 'no-answer': 0, 'not-applicable': 0}      GB  \n",
       "2  {'idk': 0, 'no-answer': 0, 'not-applicable': 0}      GB  \n",
       "3  {'no-answer': 2, 'not-applicable': 2, 'idk': 1}      US  \n",
       "4  {'no-answer': 1, 'idk': 1, 'not-applicable': 0}      IR  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_dataset_saq.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fff86-6a3e-4072-a8b7-df02fbfe7094",
   "metadata": {},
   "source": [
    "## FineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49746021-3b97-4bf0-8855-9ea2a38028dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_clean_answer(ann):\n",
    "    try:\n",
    "        ann_list = ast.literal_eval(ann)\n",
    "        if isinstance(ann_list, list) and ann_list:\n",
    "            en_answers = ann_list[0].get(\"en_answers\", [])\n",
    "            if not en_answers:\n",
    "                return \"idk\"\n",
    "\n",
    "            ans = unicodedata.normalize(\"NFKD\", en_answers[0].lower())\n",
    "            ans = re.sub(r\"[^\\w\\s]\", \"\", ans)\n",
    "            ans = re.sub(r\"\\s+\", \" \", ans).strip()\n",
    "\n",
    "            return ans if ans else \"idk\"\n",
    "    except Exception:\n",
    "        return \"idk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a756385-00fd-4fae-a1a8-78bbba82975d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_question</th>\n",
       "      <th>country</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the typical sports played in Iran's s...</td>\n",
       "      <td>IR</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which region of UK is well known for its theat...</td>\n",
       "      <td>GB</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At what age do kids start preschool in UK? (Pr...</td>\n",
       "      <td>GB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What traditional festival accessories do peopl...</td>\n",
       "      <td>US</td>\n",
       "      <td>fourth of july clothes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the duration of compulsory education i...</td>\n",
       "      <td>IR</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         en_question country  \\\n",
       "0  What are the typical sports played in Iran's s...      IR   \n",
       "1  Which region of UK is well known for its theat...      GB   \n",
       "2  At what age do kids start preschool in UK? (Pr...      GB   \n",
       "3  What traditional festival accessories do peopl...      US   \n",
       "4  What is the duration of compulsory education i...      IR   \n",
       "\n",
       "                   answer  \n",
       "0                football  \n",
       "1                  london  \n",
       "2                       3  \n",
       "3  fourth of july clothes  \n",
       "4                       8  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"answer\"] = train_df[\"annotations\"].apply(extract_clean_answer)\n",
    "train_df = train_df[[\"en_question\", \"country\", \"answer\"]]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f37a06-0f9d-4a48-ba11-db02b031a9e5",
   "metadata": {},
   "source": [
    "# Load the model (Llama-8B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a6300-b87d-4b5c-a9c1-1deb92764c99",
   "metadata": {},
   "source": [
    "Note that you need to be on the partition with GPU (e.g. capella, alpha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af8e853e-56db-406a-a80e-3654603f9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af3984-71f5-44d7-a1d7-11dd828e867b",
   "metadata": {},
   "source": [
    "This is the model which doesn't require requesting access. If you have the access to the Llama-8B model, you can use it instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0f414f9-3127-48a1-9359-8a98cf0d6a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:10<00:00, 32.58s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18b017-a673-4464-82ae-be34dd52210d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58ca6e4b-c606-4e60-a474-4c1250a4757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAQDataset(TorchDataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        \"\"\"\n",
    "        df: pandas DataFrame with columns ['en_question', 'country', 'answer']\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Prompt only includes question + country\n",
    "        prompt_text = f\"Answer the following question using ONLY ONE WORD or ONE NUMBER.\\nCountry: {row['country']}\\nQuestion: {row['en_question']}\\nAnswer:\"\n",
    "\n",
    "        answer = row[\"answer\"] if pd.notna(row[\"answer\"]) else \"idk\"\n",
    "        full_text = prompt_text + \" \" + answer\n",
    "\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            full_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Mask the prompt tokens in labels\n",
    "        prompt_len = self.tokenizer(prompt_text, add_special_tokens=False)[\"input_ids\"]\n",
    "        labels = enc[\"input_ids\"].clone()\n",
    "        labels[0, :len(prompt_len)] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": labels.squeeze(0),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "becd0f84-0769-49d5-aed9-4a93b2a13d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SAQDataset(train_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11e2d258-a30e-4e98-bcc7-65a837fa30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample 0 ---\n",
      "Input:  <|begin_of_text|>Answer the following question using ONLY ONE WORD or ONE NUMBER.\n",
      "Country: IR\n",
      "Question: What are the typical sports played in Iran's school sports day?\n",
      "Answer: football\n",
      "Label:  : football\n",
      "--------------------------------------------------\n",
      "--- Sample 1 ---\n",
      "Input:  <|begin_of_text|>Answer the following question using ONLY ONE WORD or ONE NUMBER.\n",
      "Country: GB\n",
      "Question: Which region of UK is well known for its theatrical performances?\n",
      "Answer: london\n",
      "Label:  : london\n",
      "--------------------------------------------------\n",
      "--- Sample 2 ---\n",
      "Input:  <|begin_of_text|>Answer the following question using ONLY ONE WORD or ONE NUMBER.\n",
      "Country: GB\n",
      "Question: At what age do kids start preschool in UK? (Provide Arabic numerals (e.g., 12) only.)\n",
      "Answer: 3\n",
      "Label:  : 3\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def decode_without_special(ids):\n",
    "    return tokenizer.decode([i for i in ids if i != tokenizer.pad_token_id and i != -100]).strip()\n",
    "\n",
    "for i in range(3):\n",
    "    sample = train_dataset[i]\n",
    "    decoded_input = decode_without_special(sample[\"input_ids\"])\n",
    "    decoded_label = decode_without_special(sample[\"labels\"])\n",
    "    print(f\"--- Sample {i} ---\")\n",
    "    print(\"Input: \", decoded_input)\n",
    "    print(\"Label: \", decoded_label)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d74e2-ff21-4539-ad18-232e6cdd1fa7",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bf8d4a3-1190-421d-8dc2-ce466d2eabbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15eec3eb-78c2-4a7d-8798-407ca3efea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3_saq_lora\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "198f2dcd-9754-4126-a429-70796ef03792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 04:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=252, training_loss=0.06992823012646228, metrics={'train_runtime': 323.8279, 'train_samples_per_second': 12.349, 'train_steps_per_second': 0.778, 'total_flos': 4.614059508262502e+16, 'train_loss': 0.06992823012646228, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239aa0eb-1877-45de-baa4-d4150a05dda4",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "270943f4-e81a-4897-bb59-0c9f2157a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_generation(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text.lower())\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.split()[0] if text else \"idk\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30625446-e851-4175-a1e5-0e0d2b5462c4",
   "metadata": {},
   "source": [
    "# SAQ Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef080235-f666-41fb-bf93-a97f6a287b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saq_predict(question, country, max_new_tokens=5):\n",
    "    prompt_text = f\"Answer the following question using ONLY ONE WORD or ONE NUMBER.\\nCountry: {country}\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Return only the first word of the generated answer\n",
    "    cleaned = unicodedata.normalize(\"NFKD\", decoded.lower())\n",
    "    cleaned = re.sub(r\"[^\\w\\s]\", \"\", cleaned)\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    return cleaned.split()[0] if cleaned else \"idk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6a774-fa51-4113-bf7d-d5a9d78f97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_dataset_saq.csv\")\n",
    "\n",
    "test_df[\"answer\"] = test_df.apply(\n",
    "    lambda row: saq_predict(row[\"en_question\"], row[\"country\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "test_df[[\"ID\", \"answer\"]].to_csv(\n",
    "    \"saq_prediction.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "test_df[[\"ID\", \"answer\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090eb4ae-66c9-48a3-853a-9b34404729d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "saq = pd.read_csv(\"test_dataset_saq.csv\")\n",
    "\n",
    "saq = saq.sample(n=10, random_state=12)\n",
    "saq = saq[[\"ID\", \"en_question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a5f58-a5de-46aa-8832-0ba9233ca1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for q in saq[\"en_question\"]:\n",
    "    answer = saq_func(q)\n",
    "    preds.append(answer)\n",
    "\n",
    "saq[\"answer\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde3feb2-d5ef-489b-8285-7ed68559bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saq_submission = saq[[\"ID\", \"answer\"]]\n",
    "saq_submission.to_csv(\"saq_prediction.tsv\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
